# Google File System

[阅读笔记](GFS阅读笔记.md)

![GFS架构](images\GFS架构.png)

​	GFS 是典型的**中心化架构**设计。 GFS 集群由一个 master 和多个块服务器组成，可被多个客户端访问。

​	优点： master 掌控整个文件系统的元数据，控制所有数据变更和后台活动，管理和维护起来比较简单。

​	缺点：

+ 性能瓶颈。如果大量操作都需要 master 的参与， master 很可能成为性能瓶颈。因此，GFS 的很多设计都以降低 master 的参与程度为目标，比如 master 只为数据读取提供元数据（缓存机制进一步减少交互）、对并发操作使用租约机制等。

+ 单点故障。如果 master 出现问题，整个系统可能瘫痪。为此 GFS 采取了许多措施来增强系统的可靠性，比如利用操作日志和检查点重建文件系统状态（在多个远程机器上保存副本）、设置备用 master 、利用影子 master提供只读服务等。

![写操作的控制流和数据流](images\写操作的控制流和数据流.png)

​	GFS 在设计中几种常见的优化方向：

+ 缓存和数据预取，减少磁盘 I/O 次数和通信频率，缩短响应时间。
  + 客户端缓存。缓存元数据。
  + 元数据预取。master 在客户端发送请求时额外提供后续块的信息。
  + 块服务器缓存。利用 linux Buffer Cache 缓存文件热数据。
  + 缓存也会带来数据不一致的问题，需要额外的逻辑来处理，比如元数据缓存可能导致客户端读到过期的副本。

+ 延迟策略，异步批量处理。
  + 延迟内存分配。聚少成多，缓解数据块内部碎片。
  + 垃圾回收。先删除后回收，集中处理，简单可靠，文件可恢复。
  + 写时复制。用于快照操作，避免不必要的复制。
  + 读写锁的延迟分配。
  + 这种滞后性也会带来一些不便，比如垃圾回收使得用户无法对存储空间进行微调。

+ 内存+压缩技术，提高存储效率和访问速度。
  + 元数据存放在内存中， master 相关操作效率很高。
  + 为了缓解内存的容量不足，检查点以 [B 树](B-树.md)的形式紧凑存放，文件名采用[前缀压缩](前缀压缩.md)技术存放，数据块采用较大的尺寸以减少元数据量。
  + 检查和也存放在内存，查找和比较无需任何I/O操作。
  + 缺点是内存容量有限，而且断电数据会丢失，比如重要的元数据变更就使用了日志实现持久化存储。

+ 批量处理，均摊成本，提高系统吞吐量。
  + 延迟内存分配。可减少磁盘寻道次数。
  + 垃圾回收。垃圾定期集中清理，合并到后台活动，效率提高，且便于调度。
  + 数据流水线传输。连续发送多个数据段，无需等待确认。
  + 日志合并写入。可避免频繁刷盘。
  + 客户端一次性请求多个块。可降低通信频率和磁盘 I/O 次数。

