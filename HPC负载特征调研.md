# 负载特征调研

## 1. 前置知识

（1）Defensive Write（防御性写入）

定义：Defensive Write 指在计算过程中**主动将中间状态或关键数据写入存储**的操作，目的是为了防止因系统故障（如节点崩溃、断电、网络中断等）导致数据丢失或计算任务前功尽弃。

作用：通过定期保存中间结果，即使发生故障，也可以从最近的检查点恢复，而非从头开始。

## 2. 常规超算

### 2.1 参考资料

| #    | 文献类型              | 标题                                                         | 贡献                                                         |
| ---- | --------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1    | 期刊论文（TPDS’1996） | File-Access Characteristics of Parallel Scientific Workloads | 从**计算节点**角度观察并行科学应用的工作负载                 |
| 2    | 技术报告（2004）      | File System Workload Analysis For Large Scale Scientific Computing Applications | 从IOR2基准和物理模拟程序的运行中分析文件和工作负载的特征     |
| 3    | 会议论文（SC‘2012）   | Characterizing Output Bottlenecks in a Supercomputer         | 建立数学模型量化 Lustre 文件系统在超算负载（突发性输出）下的性能表现 |
| 4    | 会议论文（HiPC’2020） | Understanding HPC Application I/O Behavior  Using System Level Statistics | 从LLNL的两个计算集群中分别收集并分析**文件系统级**统计信息   |
| 5    | 会议论文（MSST'2013)  | Optimizing a hybrid SSD/HDD HPC storage system  based on file size distributions | 统计了HPC环境下文件大小的分布规律                            |

### 2.2 总结

+ 在所有请求中小规模请求占主导，但大部分数据通过少数大规模请求传输（1，2）。
+ 大多数文件是小文件，但大部分容量被大文件占用（5）。
+ 许多作业写入数据总量很大，但单次写入数据量少（4）。
+ 写操作占主导（1，3），常见的写密集型负载包括状态快照和防御性写（如重启文件），且大部分数据写入后不会再被访问（3）。
+ 应用呈现突发的访问模式（2，3，4），且写较读往往更密集（2），其中既包括中间结果和检查点保存产生的TB级输出（3），也包括KB级的小型突发写（4）。
+ 计算节点之间有大量的共享数据块（只读文件的数据共享比例相当高，只写文件较低）（1），因此在I/O节点处设置缓存可能会有助于提高系统性能。

## 3 超算智算

### 3.1 参考资料

| #    | 文献类型                   | 标题                           | 贡献                                                         |
| ---- | -------------------------- | ------------------------------ | ------------------------------------------------------------ |
| 1    | 期刊论文（计算机学报2025） | 面向深度学习的数据存储技术综述 | 总结了深度学习的数据特点,包括数据集和模型的规模与类型,以及**数据准备**和**模型计算**阶段的数据访问模式 |

### 3.2 总结

（1）数据特点

+ 数据集总量大，但主要由小文件组成（数百字节到数百KB）。
+ 模型的中间计算结果存在显著的稀疏性（ReLU，Dropout）。

（2）数据访问模式

I. 数据准备阶段：

+ **随机**读取训练集，**顺序**读取测试集。训练阶段，程序仅在数据集上执行读操作。
+ 大量的元数据访问，包括训练开始前和每次迭代开始前的相关访问。
+ 大量的数据共享。同一训练任务的不同轮次需要访问相同的数据集，不同训练任务也可能会使用相同的数据集或者同一数据集的不同版本。

II. 模型计算阶段：

+ 参数访问的不均匀。一种是来源于数据本身的倾斜分布，另一种是来源于对参数访问的采样。

+ 大量的数据复用。在每次迭代中，反向传播会复用前向传播的计算结果。
+ 少量的写入操作，包括训练日志的写入和检查点的创建（仅追加写，无覆盖写和并发写）。

其他：

+ 随着机器学习工作负载的增加，读密集型工作负载的数量总体呈上升趋势（常规超算 1）。
